{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import gensim, logging\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, ldamodel\n",
    "\n",
    "import spacy\n",
    "# For future ref, the only install that's ever worked for spacy: conda install -c conda-forge spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emily C. Duncan received two patents in 1903 and 1904 for banking-related '\n",
      " 'calculators.[1] Duncan was born in 1849 in Coral, Illinois as Emily '\n",
      " 'Cornelius Forbes and later resided in Centralia, Wisconsin (which later '\n",
      " 'became Wisconsin Rapids) and Jennings, Louisiana. She invented new banking '\n",
      " 'calculators and was mentioned in Inventive Age magazine in February 1905. '\n",
      " 'Duncan was recognized as one of many women who worked in the age of '\n",
      " 'technology before the actual computer.[2] She was married to inventor James '\n",
      " 'Eugene Duncan and although he was believed to be the only inventor in the '\n",
      " 'family written accounts from her granddaughter indicated she assisted her '\n",
      " 'husband with numerous inventions.[3] Based on her written statement provided '\n",
      " 'in the original patent application she stated that her goal was to provide a '\n",
      " '“simple and readily understood structure with which computations ordinarily '\n",
      " 'requiring considerable time and care may be accurately and quickly made”.[4] '\n",
      " 'The other objective of her invention was “to provide a device of the above '\n",
      " 'character in which parts may be readily substituted, so that computations of '\n",
      " 'different kinds may be made”.[4] The first apparatus was intended for '\n",
      " 'computing interest in 1 at six, seven, or eight per cent. The calculator was '\n",
      " 'first designed to easily be used by any mathematician, but her original '\n",
      " 'patent provided detailed illustration of two apparatuses with details '\n",
      " 'explaining how the calculator was to be operated. The invention was designed '\n",
      " 'more specifically for computing in hundreds[4] In 1904, she received another '\n",
      " 'patent for an invention relating to improvements in calculators. Her '\n",
      " 'objective of this invention was to improve the construction of '\n",
      " 'time-calculators and to provide a more durable device designed primarily for '\n",
      " 'determining the number of days between any two dates within a year with '\n",
      " 'absolute accuracy.[5]']\n"
     ]
    }
   ],
   "source": [
    "duncan = open('duncan.txt','r')\n",
    "#print(duncan.read())\n",
    "\n",
    "duncan = [re.sub(\"\\'\", \"\", sent) for sent in duncan]\n",
    "pprint(duncan[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['emily', 'duncan', 'received', 'two', 'patents', 'in', 'and', 'for', 'banking', 'related', 'calculators', 'duncan', 'was', 'born', 'in', 'in', 'coral', 'illinois', 'as', 'emily', 'cornelius', 'forbes', 'and', 'later', 'resided', 'in', 'centralia', 'wisconsin', 'which', 'later', 'became', 'wisconsin', 'rapids', 'and', 'jennings', 'louisiana', 'she', 'invented', 'new', 'banking', 'calculators', 'and', 'was', 'mentioned', 'in', 'inventive', 'age', 'magazine', 'in', 'february', 'duncan', 'was', 'recognized', 'as', 'one', 'of', 'many', 'women', 'who', 'worked', 'in', 'the', 'age', 'of', 'technology', 'before', 'the', 'actual', 'computer', 'she', 'was', 'married', 'to', 'inventor', 'james', 'eugene', 'duncan', 'and', 'although', 'he', 'was', 'believed', 'to', 'be', 'the', 'only', 'inventor', 'in', 'the', 'family', 'written', 'accounts', 'from', 'her', 'granddaughter', 'indicated', 'she', 'assisted', 'her', 'husband', 'with', 'numerous', 'inventions', 'based', 'on', 'her', 'written', 'statement', 'provided', 'in', 'the', 'original', 'patent', 'application', 'she', 'stated', 'that', 'her', 'goal', 'was', 'to', 'provide', 'simple', 'and', 'readily', 'understood', 'structure', 'with', 'which', 'computations', 'ordinarily', 'requiring', 'considerable', 'time', 'and', 'care', 'may', 'be', 'accurately', 'and', 'quickly', 'made', 'the', 'other', 'objective', 'of', 'her', 'invention', 'was', 'to', 'provide', 'device', 'of', 'the', 'above', 'character', 'in', 'which', 'parts', 'may', 'be', 'readily', 'substituted', 'so', 'that', 'computations', 'of', 'different', 'kinds', 'may', 'be', 'made', 'the', 'first', 'apparatus', 'was', 'intended', 'for', 'computing', 'interest', 'in', 'at', 'six', 'seven', 'or', 'eight', 'per', 'cent', 'the', 'calculator', 'was', 'first', 'designed', 'to', 'easily', 'be', 'used', 'by', 'any', 'mathematician', 'but', 'her', 'original', 'patent', 'provided', 'detailed', 'illustration', 'of', 'two', 'apparatuses', 'with', 'details', 'explaining', 'how', 'the', 'calculator', 'was', 'to', 'be', 'operated', 'the', 'invention', 'was', 'designed', 'more', 'specifically', 'for', 'computing', 'in', 'hundreds', 'in', 'she', 'received', 'another', 'patent', 'for', 'an', 'invention', 'relating', 'to', 'improvements', 'in', 'calculators', 'her', 'objective', 'of', 'this', 'invention', 'was', 'to', 'improve', 'the', 'construction', 'of', 'time', 'calculators', 'and', 'to', 'provide', 'more', 'durable', 'device', 'designed', 'primarily', 'for', 'determining', 'the', 'number', 'of', 'days', 'between', 'any', 'two', 'dates', 'within', 'year', 'with', 'absolute', 'accuracy']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    " \n",
    "data_words = list(sent_to_words(duncan))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marieskoczylas/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emily', 'duncan', 'received', 'two', 'patents', 'in', 'and', 'for', 'banking', 'related', 'calculators', 'duncan', 'was', 'born', 'in', 'in', 'coral', 'illinois', 'as', 'emily', 'cornelius', 'forbes', 'and', 'later', 'resided', 'in', 'centralia', 'wisconsin', 'which', 'later', 'became', 'wisconsin', 'rapids', 'and', 'jennings', 'louisiana', 'she', 'invented', 'new', 'banking', 'calculators', 'and', 'was', 'mentioned', 'in', 'inventive', 'age', 'magazine', 'in', 'february', 'duncan', 'was', 'recognized', 'as', 'one', 'of', 'many', 'women', 'who', 'worked', 'in', 'the', 'age', 'of', 'technology', 'before', 'the', 'actual', 'computer', 'she', 'was', 'married', 'to', 'inventor', 'james', 'eugene', 'duncan', 'and', 'although', 'he', 'was', 'believed', 'to', 'be', 'the', 'only', 'inventor', 'in', 'the', 'family', 'written', 'accounts', 'from', 'her', 'granddaughter', 'indicated', 'she', 'assisted', 'her', 'husband', 'with', 'numerous', 'inventions', 'based', 'on', 'her', 'written', 'statement', 'provided', 'in', 'the', 'original', 'patent', 'application', 'she', 'stated', 'that', 'her', 'goal', 'was', 'to', 'provide', 'simple', 'and', 'readily', 'understood', 'structure', 'with', 'which', 'computations', 'ordinarily', 'requiring', 'considerable', 'time', 'and', 'care', 'may', 'be', 'accurately', 'and', 'quickly', 'made', 'the', 'other', 'objective', 'of', 'her', 'invention', 'was', 'to', 'provide', 'device', 'of', 'the', 'above', 'character', 'in', 'which', 'parts', 'may', 'be', 'readily', 'substituted', 'so', 'that', 'computations', 'of', 'different', 'kinds', 'may', 'be', 'made', 'the', 'first', 'apparatus', 'was', 'intended', 'for', 'computing', 'interest', 'in', 'at', 'six', 'seven', 'or', 'eight', 'per', 'cent', 'the', 'calculator', 'was', 'first', 'designed', 'to', 'easily', 'be', 'used', 'by', 'any', 'mathematician', 'but', 'her', 'original', 'patent', 'provided', 'detailed', 'illustration', 'of', 'two', 'apparatuses', 'with', 'details', 'explaining', 'how', 'the', 'calculator', 'was', 'to', 'be', 'operated', 'the', 'invention', 'was', 'designed', 'more', 'specifically', 'for', 'computing', 'in', 'hundreds', 'in', 'she', 'received', 'another', 'patent', 'for', 'an', 'invention', 'relating', 'to', 'improvements', 'in', 'calculators', 'her', 'objective', 'of', 'this', 'invention', 'was', 'to', 'improve', 'the', 'construction', 'of', 'time', 'calculators', 'and', 'to', 'provide', 'more', 'durable', 'device', 'designed', 'primarily', 'for', 'determining', 'the', 'number', 'of', 'days', 'between', 'any', 'two', 'dates', 'within', 'year', 'with', 'absolute', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatizations(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://space.io/api/annotation\"\"\"\n",
    "    \n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['emily', 'duncan', 'received', 'two', 'patents', 'banking', 'related', 'calculators', 'duncan', 'born', 'coral', 'illinois', 'emily', 'cornelius', 'forbes', 'later', 'resided', 'centralia', 'wisconsin', 'later', 'became', 'wisconsin', 'rapids', 'jennings', 'louisiana', 'invented', 'new', 'banking', 'calculators', 'mentioned', 'inventive', 'age', 'magazine', 'february', 'duncan', 'recognized', 'one', 'many', 'women', 'worked', 'age', 'technology', 'actual', 'computer', 'married', 'inventor', 'james', 'eugene', 'duncan', 'although', 'believed', 'inventor', 'family', 'written', 'accounts', 'granddaughter', 'indicated', 'assisted', 'husband', 'numerous', 'inventions', 'based', 'written', 'statement', 'provided', 'original', 'patent', 'application', 'stated', 'goal', 'provide', 'simple', 'readily', 'understood', 'structure', 'computations', 'ordinarily', 'requiring', 'considerable', 'time', 'care', 'may', 'accurately', 'quickly', 'made', 'objective', 'invention', 'provide', 'device', 'character', 'parts', 'may', 'readily', 'substituted', 'computations', 'different', 'kinds', 'may', 'made', 'first', 'apparatus', 'intended', 'computing', 'interest', 'six', 'seven', 'eight', 'per', 'cent', 'calculator', 'first', 'designed', 'easily', 'used', 'mathematician', 'original', 'patent', 'provided', 'detailed', 'illustration', 'two', 'apparatuses', 'details', 'explaining', 'calculator', 'operated', 'invention', 'designed', 'specifically', 'computing', 'hundreds', 'received', 'another', 'patent', 'invention', 'relating', 'improvements', 'calculators', 'objective', 'invention', 'improve', 'construction', 'time', 'calculators', 'provide', 'durable', 'device', 'designed', 'primarily', 'determining', 'number', 'days', 'two', 'dates', 'within', 'year', 'absolute', 'accuracy']]\n"
     ]
    }
   ],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner']) # Doesn't work because spacy and 'en' don't work\n",
    "\n",
    "#data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_words_bigrams[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 4), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 3), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 4), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 4), (62, 1), (63, 1), (64, 2), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 2), (71, 1), (72, 1), (73, 1), (74, 1), (75, 3), (76, 1), (77, 1), (78, 1), (79, 1), (80, 2), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 3), (87, 1), (88, 1), (89, 1), (90, 3), (91, 2), (92, 1), (93, 1), (94, 2), (95, 2), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 2), (111, 3), (112, 1), (113, 1), (114, 2), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "texts = data_words_bigrams\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('absolute', 1),\n",
       "  ('accounts', 1),\n",
       "  ('accuracy', 1),\n",
       "  ('accurately', 1),\n",
       "  ('actual', 1),\n",
       "  ('age', 2),\n",
       "  ('although', 1),\n",
       "  ('another', 1),\n",
       "  ('apparatus', 1),\n",
       "  ('apparatuses', 1),\n",
       "  ('application', 1),\n",
       "  ('assisted', 1),\n",
       "  ('banking', 2),\n",
       "  ('based', 1),\n",
       "  ('became', 1),\n",
       "  ('believed', 1),\n",
       "  ('born', 1),\n",
       "  ('calculator', 2),\n",
       "  ('calculators', 4),\n",
       "  ('care', 1),\n",
       "  ('cent', 1),\n",
       "  ('centralia', 1),\n",
       "  ('character', 1),\n",
       "  ('computations', 2),\n",
       "  ('computer', 1),\n",
       "  ('computing', 2),\n",
       "  ('considerable', 1),\n",
       "  ('construction', 1),\n",
       "  ('coral', 1),\n",
       "  ('cornelius', 1),\n",
       "  ('dates', 1),\n",
       "  ('days', 1),\n",
       "  ('designed', 3),\n",
       "  ('detailed', 1),\n",
       "  ('details', 1),\n",
       "  ('determining', 1),\n",
       "  ('device', 2),\n",
       "  ('different', 1),\n",
       "  ('duncan', 4),\n",
       "  ('durable', 1),\n",
       "  ('easily', 1),\n",
       "  ('eight', 1),\n",
       "  ('emily', 2),\n",
       "  ('eugene', 1),\n",
       "  ('explaining', 1),\n",
       "  ('family', 1),\n",
       "  ('february', 1),\n",
       "  ('first', 2),\n",
       "  ('forbes', 1),\n",
       "  ('goal', 1),\n",
       "  ('granddaughter', 1),\n",
       "  ('hundreds', 1),\n",
       "  ('husband', 1),\n",
       "  ('illinois', 1),\n",
       "  ('illustration', 1),\n",
       "  ('improve', 1),\n",
       "  ('improvements', 1),\n",
       "  ('indicated', 1),\n",
       "  ('intended', 1),\n",
       "  ('interest', 1),\n",
       "  ('invented', 1),\n",
       "  ('invention', 4),\n",
       "  ('inventions', 1),\n",
       "  ('inventive', 1),\n",
       "  ('inventor', 2),\n",
       "  ('james', 1),\n",
       "  ('jennings', 1),\n",
       "  ('kinds', 1),\n",
       "  ('later', 2),\n",
       "  ('louisiana', 1),\n",
       "  ('made', 2),\n",
       "  ('magazine', 1),\n",
       "  ('many', 1),\n",
       "  ('married', 1),\n",
       "  ('mathematician', 1),\n",
       "  ('may', 3),\n",
       "  ('mentioned', 1),\n",
       "  ('new', 1),\n",
       "  ('number', 1),\n",
       "  ('numerous', 1),\n",
       "  ('objective', 2),\n",
       "  ('one', 1),\n",
       "  ('operated', 1),\n",
       "  ('ordinarily', 1),\n",
       "  ('original', 2),\n",
       "  ('parts', 1),\n",
       "  ('patent', 3),\n",
       "  ('patents', 1),\n",
       "  ('per', 1),\n",
       "  ('primarily', 1),\n",
       "  ('provide', 3),\n",
       "  ('provided', 2),\n",
       "  ('quickly', 1),\n",
       "  ('rapids', 1),\n",
       "  ('readily', 2),\n",
       "  ('received', 2),\n",
       "  ('recognized', 1),\n",
       "  ('related', 1),\n",
       "  ('relating', 1),\n",
       "  ('requiring', 1),\n",
       "  ('resided', 1),\n",
       "  ('seven', 1),\n",
       "  ('simple', 1),\n",
       "  ('six', 1),\n",
       "  ('specifically', 1),\n",
       "  ('stated', 1),\n",
       "  ('statement', 1),\n",
       "  ('structure', 1),\n",
       "  ('substituted', 1),\n",
       "  ('technology', 1),\n",
       "  ('time', 2),\n",
       "  ('two', 3),\n",
       "  ('understood', 1),\n",
       "  ('used', 1),\n",
       "  ('wisconsin', 2),\n",
       "  ('within', 1),\n",
       "  ('women', 1),\n",
       "  ('worked', 1),\n",
       "  ('written', 2),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (1,\n",
      "  '0.008*\"duncan\" + 0.008*\"calculators\" + 0.008*\"invention\" + 0.008*\"age\" + '\n",
      "  '0.008*\"two\" + 0.008*\"provide\" + 0.008*\"may\" + 0.008*\"later\" + '\n",
      "  '0.008*\"designed\" + 0.008*\"emily\"'),\n",
      " (2,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (3,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (4,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (5,\n",
      "  '0.009*\"invention\" + 0.009*\"calculators\" + 0.009*\"may\" + 0.009*\"two\" + '\n",
      "  '0.009*\"duncan\" + 0.008*\"provide\" + 0.008*\"device\" + 0.008*\"patent\" + '\n",
      "  '0.008*\"designed\" + 0.008*\"provided\"'),\n",
      " (6,\n",
      "  '0.009*\"invention\" + 0.009*\"two\" + 0.009*\"calculators\" + 0.008*\"patent\" + '\n",
      "  '0.008*\"duncan\" + 0.008*\"designed\" + 0.008*\"may\" + 0.008*\"computations\" + '\n",
      "  '0.008*\"provide\" + 0.008*\"written\"'),\n",
      " (7,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (8,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (9,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (10,\n",
      "  '0.009*\"calculators\" + 0.009*\"invention\" + 0.009*\"duncan\" + 0.009*\"designed\" '\n",
      "  '+ 0.009*\"two\" + 0.009*\"provide\" + 0.009*\"may\" + 0.009*\"age\" + '\n",
      "  '0.008*\"calculator\" + 0.008*\"made\"'),\n",
      " (11,\n",
      "  '0.025*\"calculators\" + 0.025*\"duncan\" + 0.025*\"invention\" + 0.019*\"designed\" '\n",
      "  '+ 0.019*\"provide\" + 0.019*\"two\" + 0.019*\"patent\" + 0.019*\"may\" + '\n",
      "  '0.013*\"first\" + 0.013*\"readily\"'),\n",
      " (12,\n",
      "  '0.009*\"duncan\" + 0.009*\"invention\" + 0.009*\"calculators\" + 0.009*\"designed\" '\n",
      "  '+ 0.009*\"patent\" + 0.009*\"banking\" + 0.009*\"two\" + 0.009*\"provide\" + '\n",
      "  '0.009*\"time\" + 0.009*\"may\"'),\n",
      " (13,\n",
      "  '0.009*\"invention\" + 0.009*\"duncan\" + 0.009*\"patent\" + 0.009*\"calculators\" + '\n",
      "  '0.009*\"may\" + 0.009*\"provide\" + 0.009*\"objective\" + 0.009*\"two\" + '\n",
      "  '0.008*\"wisconsin\" + 0.008*\"emily\"'),\n",
      " (14,\n",
      "  '0.009*\"duncan\" + 0.009*\"calculators\" + 0.009*\"invention\" + 0.009*\"patent\" + '\n",
      "  '0.009*\"may\" + 0.009*\"two\" + 0.009*\"designed\" + 0.009*\"wisconsin\" + '\n",
      "  '0.009*\"provide\" + 0.009*\"emily\"'),\n",
      " (15,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (16,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (17,\n",
      "  '0.008*\"operated\" + 0.008*\"original\" + 0.008*\"number\" + 0.008*\"numerous\" + '\n",
      "  '0.008*\"objective\" + 0.008*\"one\" + 0.008*\"mentioned\" + 0.008*\"ordinarily\" + '\n",
      "  '0.008*\"per\" + 0.008*\"patent\"'),\n",
      " (18,\n",
      "  '0.009*\"calculators\" + 0.009*\"invention\" + 0.008*\"patent\" + 0.008*\"provide\" '\n",
      "  '+ 0.008*\"later\" + 0.008*\"may\" + 0.008*\"designed\" + 0.008*\"device\" + '\n",
      "  '0.008*\"duncan\" + 0.008*\"made\"'),\n",
      " (19,\n",
      "  '0.009*\"invention\" + 0.009*\"duncan\" + 0.008*\"may\" + 0.008*\"provide\" + '\n",
      "  '0.008*\"calculators\" + 0.008*\"two\" + 0.008*\"calculator\" + 0.008*\"patent\" + '\n",
      "  '0.008*\"original\" + 0.008*\"provided\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.44170537213736\n",
      "\n",
      "Coherence Score:  0.57082816050018\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))\n",
    "# A measure of how good the model is. The lower the better. Mine here is -6.44\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marieskoczylas/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'complex' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data, kwds)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text/html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     formatter.for_type(PreparedData,\n\u001b[0;32m--> 313\u001b[0;31m                        lambda data, kwds=kwargs: prepared_data_to_html(data, **kwds))\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36mprepared_data_to_html\u001b[0;34m(data, d3_url, ldavis_url, ldavis_css_url, template_type, visid, use_http)\u001b[0m\n\u001b[1;32m    176\u001b[0m                            \u001b[0md3_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md3_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                            \u001b[0mldavis_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mldavis_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                            \u001b[0mvis_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                            ldavis_css_url=ldavis_css_url)\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNumPyEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/site-packages/pyLDAvis/utils.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp_environ/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'complex' is not JSON serializable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=                                 x        y  topics  cluster       Freq\n",
       "topic                                                                  \n",
       "11      (-0.019758555608636322+0j)  (-0+0j)       1        1  99.695465\n",
       "14     (-0.0004720848025382811+0j)       0j       2        1   0.019222\n",
       "12     (-4.583917512499793e-06+0j)  (-0+0j)       3        1   0.019197\n",
       "13      (0.0003080060622126998+0j)       0j       4        1   0.019164\n",
       "10       (0.000488589584617799+0j)  (-0+0j)       5        1   0.019145\n",
       "5       (0.0005248740858602829+0j)       0j       6        1   0.019138\n",
       "6       (0.0008891729737140298+0j)       0j       7        1   0.019079\n",
       "18      (0.0009354088943457972+0j)       0j       8        1   0.019062\n",
       "19      (0.0009929990740180491+0j)       0j       9        1   0.019055\n",
       "1       (0.0012068402829685514+0j)  (-0+0j)      10        1   0.018974\n",
       "2       (0.0014889333370949884+0j)  (-0+0j)      11        1   0.013250\n",
       "3       (0.0014889333370949884+0j)  (-0+0j)      12        1   0.013250\n",
       "4       (0.0014889333370949884+0j)  (-0+0j)      13        1   0.013250\n",
       "9       (0.0014889333370949884+0j)  (-0+0j)      14        1   0.013250\n",
       "7       (0.0014889333370949884+0j)  (-0+0j)      15        1   0.013250\n",
       "8       (0.0014889333370949884+0j)  (-0+0j)      16        1   0.013250\n",
       "15      (0.0014889333370949887+0j)  (-0+0j)      17        1   0.013250\n",
       "16       (0.001488933337094989+0j)  (-0+0j)      18        1   0.013250\n",
       "17      (0.0014889333370949895+0j)  (-0+0j)      19        1   0.013250\n",
       "0         (0.00148893333709499+0j)  (-0+0j)      20        1   0.013250, topic_info=     Category      Freq           Term     Total  loglift  logprob\n",
       "term                                                              \n",
       "38    Default  3.000000         duncan  3.000000  30.0000  30.0000\n",
       "18    Default  3.000000    calculators  3.000000  29.0000  29.0000\n",
       "61    Default  3.000000      invention  3.000000  28.0000  28.0000\n",
       "32    Default  2.000000       designed  2.000000  27.0000  27.0000\n",
       "90    Default  2.000000        provide  2.000000  26.0000  26.0000\n",
       "111   Default  2.000000            two  2.000000  25.0000  25.0000\n",
       "86    Default  2.000000         patent  2.000000  24.0000  24.0000\n",
       "75    Default  2.000000            may  2.000000  23.0000  23.0000\n",
       "47    Default  1.000000          first  1.000000  22.0000  22.0000\n",
       "94    Default  1.000000        readily  1.000000  21.0000  21.0000\n",
       "95    Default  1.000000       received  1.000000  20.0000  20.0000\n",
       "91    Default  1.000000       provided  1.000000  19.0000  19.0000\n",
       "25    Default  1.000000      computing  1.000000  18.0000  18.0000\n",
       "84    Default  1.000000       original  1.000000  17.0000  17.0000\n",
       "70    Default  1.000000           made  1.000000  16.0000  16.0000\n",
       "68    Default  1.000000          later  1.000000  15.0000  15.0000\n",
       "80    Default  1.000000      objective  1.000000  14.0000  14.0000\n",
       "118   Default  1.000000        written  1.000000  13.0000  13.0000\n",
       "5     Default  1.000000            age  1.000000  12.0000  12.0000\n",
       "23    Default  1.000000   computations  1.000000  11.0000  11.0000\n",
       "17    Default  1.000000     calculator  1.000000  10.0000  10.0000\n",
       "64    Default  1.000000       inventor  1.000000   9.0000   9.0000\n",
       "110   Default  1.000000           time  1.000000   8.0000   8.0000\n",
       "114   Default  1.000000      wisconsin  1.000000   7.0000   7.0000\n",
       "12    Default  1.000000        banking  1.000000   6.0000   6.0000\n",
       "42    Default  1.000000          emily  1.000000   5.0000   5.0000\n",
       "36    Default  1.000000         device  1.000000   4.0000   4.0000\n",
       "105   Default  1.000000         stated  1.000000   3.0000   3.0000\n",
       "4     Default  1.000000         actual  1.000000   2.0000   2.0000\n",
       "3     Default  1.000000     accurately  1.000000   1.0000   1.0000\n",
       "...       ...       ...            ...       ...      ...      ...\n",
       "59    Topic20  0.000174       interest  1.012410   0.2628  -4.7875\n",
       "104   Topic20  0.000174   specifically  1.012416   0.2628  -4.7875\n",
       "34    Topic20  0.000174        details  1.012424   0.2628  -4.7875\n",
       "71    Topic20  0.000174       magazine  1.012428   0.2628  -4.7875\n",
       "8     Topic20  0.000174      apparatus  1.012452   0.2627  -4.7875\n",
       "37    Topic20  0.000174      different  1.012458   0.2627  -4.7875\n",
       "40    Topic20  0.000174         easily  1.012471   0.2627  -4.7875\n",
       "97    Topic20  0.000174        related  1.012483   0.2627  -4.7875\n",
       "9     Topic20  0.000174    apparatuses  1.012504   0.2627  -4.7875\n",
       "118   Topic20  0.000174        written  1.972897  -0.4044  -4.7875\n",
       "31    Topic20  0.000174           days  1.012607   0.2626  -4.7875\n",
       "32    Topic20  0.000174       designed  2.934453  -0.8014  -4.7875\n",
       "35    Topic20  0.000174    determining  1.012498   0.2627  -4.7875\n",
       "36    Topic20  0.000174         device  1.972133  -0.4040  -4.7875\n",
       "38    Topic20  0.000174         duncan  3.893052  -1.0841  -4.7875\n",
       "39    Topic20  0.000174        durable  1.012568   0.2626  -4.7875\n",
       "42    Topic20  0.000174          emily  1.972169  -0.4040  -4.7875\n",
       "43    Topic20  0.000174         eugene  1.012721   0.2625  -4.7875\n",
       "44    Topic20  0.000174     explaining  1.012637   0.2625  -4.7875\n",
       "46    Topic20  0.000174       february  1.012540   0.2626  -4.7875\n",
       "47    Topic20  0.000174          first  1.973989  -0.4050  -4.7875\n",
       "48    Topic20  0.000174         forbes  1.012972   0.2622  -4.7875\n",
       "49    Topic20  0.000174           goal  1.012805   0.2624  -4.7875\n",
       "50    Topic20  0.000174  granddaughter  1.012715   0.2625  -4.7875\n",
       "51    Topic20  0.000174       hundreds  1.012592   0.2626  -4.7875\n",
       "52    Topic20  0.000174        husband  1.012487   0.2627  -4.7875\n",
       "53    Topic20  0.000174       illinois  1.012538   0.2626  -4.7875\n",
       "54    Topic20  0.000174   illustration  1.012814   0.2624  -4.7875\n",
       "55    Topic20  0.000174        improve  1.012592   0.2626  -4.7875\n",
       "56    Topic20  0.000174   improvements  1.012679   0.2625  -4.7875\n",
       "\n",
       "[1121 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "0         1  0.987865      absolute\n",
       "1         1  0.987509      accounts\n",
       "3         1  0.987026    accurately\n",
       "4         1  0.986996        actual\n",
       "5         1  1.013839           age\n",
       "6         1  0.987883      although\n",
       "7         1  0.987632       another\n",
       "8         1  0.987701     apparatus\n",
       "9         1  0.987650   apparatuses\n",
       "10        1  0.987610   application\n",
       "11        1  0.988322      assisted\n",
       "12        1  1.014095       banking\n",
       "13        1  0.987455         based\n",
       "14        1  0.987512        became\n",
       "15        1  0.987242      believed\n",
       "16        1  0.987459          born\n",
       "17        1  1.013934    calculator\n",
       "18        1  1.027395   calculators\n",
       "19        1  0.987312          care\n",
       "20        1  0.987893          cent\n",
       "21        1  0.988126     centralia\n",
       "22        1  0.987544     character\n",
       "23        1  1.013884  computations\n",
       "24        1  0.987554      computer\n",
       "25        1  1.013525     computing\n",
       "26        1  0.987802  considerable\n",
       "27        1  0.987637  construction\n",
       "28        1  0.987453         coral\n",
       "29        1  0.987523     cornelius\n",
       "30        1  0.987791         dates\n",
       "...     ...       ...           ...\n",
       "90        1  1.022403       provide\n",
       "91        1  1.013522      provided\n",
       "92        1  0.987510       quickly\n",
       "93        1  0.987819        rapids\n",
       "94        1  1.013283       readily\n",
       "95        1  1.013513      received\n",
       "96        1  0.987474    recognized\n",
       "97        1  0.987671       related\n",
       "98        1  0.987541      relating\n",
       "99        1  0.987910     requiring\n",
       "100       1  0.987743       resided\n",
       "101       1  0.987413         seven\n",
       "102       1  0.987505        simple\n",
       "103       1  0.987983           six\n",
       "104       1  0.987736  specifically\n",
       "105       1  0.986796        stated\n",
       "106       1  0.987501     statement\n",
       "107       1  0.987839     structure\n",
       "108       1  0.987669   substituted\n",
       "109       1  0.987914    technology\n",
       "110       1  1.014000          time\n",
       "111       1  1.022611           two\n",
       "112       1  0.987324    understood\n",
       "113       1  0.987565          used\n",
       "114       1  1.014072     wisconsin\n",
       "115       1  0.987587        within\n",
       "116       1  0.987519         women\n",
       "117       1  0.987336        worked\n",
       "118       1  1.013737       written\n",
       "119       1  0.987838          year\n",
       "\n",
       "[118 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[12, 15, 13, 14, 11, 6, 7, 19, 20, 2, 3, 4, 5, 10, 8, 9, 16, 17, 18, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook() \n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word) \n",
    "vis\n",
    "\n",
    "#print (pd.concat([df1, df2], sort=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
